{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def landmark_detection(image):\n",
    "\n",
    "    # laod an image then convert it to grey scale\n",
    "    img = cv2.imread(image)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # detect the face then find the landmarks\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "    faces = detector(img_gray)\n",
    "    landmark_points_faces = []\n",
    "    for face in faces:\n",
    "        landmarks = predictor(img_gray, face)\n",
    "        landmark_points = []\n",
    "        for n in range(68):\n",
    "            x = landmarks.part(n).x\n",
    "            y = landmarks.part(n).y\n",
    "            landmark_points.append((int(x), int(y)))\n",
    "\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "        landmark_points_faces.append(landmark_points)\n",
    "\n",
    "    return landmark_points_faces, img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'images/original_images/donald_trump_meme.jpg'\n",
    "landmark_points, _ = landmark_detection(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(151, 268),\n",
       "  (159, 316),\n",
       "  (170, 362),\n",
       "  (182, 405),\n",
       "  (196, 449),\n",
       "  (220, 484),\n",
       "  (260, 505),\n",
       "  (308, 515),\n",
       "  (362, 513),\n",
       "  (417, 507),\n",
       "  (467, 495),\n",
       "  (510, 473),\n",
       "  (537, 434),\n",
       "  (549, 386),\n",
       "  (553, 335),\n",
       "  (554, 282),\n",
       "  (554, 230),\n",
       "  (172, 202),\n",
       "  (189, 173),\n",
       "  (222, 159),\n",
       "  (259, 159),\n",
       "  (293, 169),\n",
       "  (349, 161),\n",
       "  (383, 143),\n",
       "  (423, 134),\n",
       "  (464, 139),\n",
       "  (493, 166),\n",
       "  (324, 200),\n",
       "  (324, 226),\n",
       "  (323, 252),\n",
       "  (323, 280),\n",
       "  (297, 322),\n",
       "  (315, 323),\n",
       "  (334, 322),\n",
       "  (354, 318),\n",
       "  (374, 314),\n",
       "  (212, 233),\n",
       "  (229, 217),\n",
       "  (251, 213),\n",
       "  (278, 224),\n",
       "  (255, 230),\n",
       "  (232, 234),\n",
       "  (387, 211),\n",
       "  (407, 195),\n",
       "  (431, 194),\n",
       "  (456, 203),\n",
       "  (434, 209),\n",
       "  (410, 211),\n",
       "  (294, 419),\n",
       "  (303, 378),\n",
       "  (321, 355),\n",
       "  (338, 356),\n",
       "  (354, 350),\n",
       "  (382, 366),\n",
       "  (406, 404),\n",
       "  (389, 414),\n",
       "  (365, 420),\n",
       "  (347, 422),\n",
       "  (329, 424),\n",
       "  (310, 422),\n",
       "  (306, 412),\n",
       "  (324, 377),\n",
       "  (340, 374),\n",
       "  (357, 372),\n",
       "  (394, 399),\n",
       "  (360, 390),\n",
       "  (343, 393),\n",
       "  (326, 394)]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmark_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(landmark_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyConvexHull(points1_faces, points2_faces):\n",
    "    \n",
    "    \n",
    "    hulls1 = []\n",
    "    hulls2 = []\n",
    "    \n",
    "    faces1 = points1_faces.shape[0]\n",
    "    faces2 = points2_faces.shape[0]\n",
    "    for face in range(faces):\n",
    "          # Find convex hull of the two landmark points\n",
    "        hull1 = []\n",
    "        hull2 = []\n",
    "        \n",
    "        points1 = points1_faces[face]\n",
    "        points2 = points2_faces[face]\n",
    "\n",
    "        hullIndex = cv2.convexHull(np.array(points2), returnPoints = False)\n",
    "\n",
    "        for i in range(len(hullIndex)):\n",
    "            hull1.append(points1[int(hullIndex[i])])\n",
    "            hull2.append(points2[int(hullIndex[i])])\n",
    "            \n",
    "        hulls1.append(hull1)\n",
    "        hulls2.append(hull2)\n",
    "\n",
    "    return hull1, hull2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateDelaunayTriangles(image, points):\n",
    "\n",
    "    img = cv2.imread(image)\n",
    "    rect = (0, 0, img.shape[1], img.shape[0])\n",
    "\n",
    "    subdiv = cv2.Subdiv2D(rect)\n",
    "    subdiv.insert(points)\n",
    "    triangleList = subdiv.getTriangleList()\n",
    "\n",
    "    delaunayTri_indexes = []\n",
    "\n",
    "\n",
    "    for t in triangleList:\n",
    "\n",
    "        pt1 = (t[0], t[1])\n",
    "        pt2 = (t[2], t[3])\n",
    "        pt3 = (t[4], t[5])\n",
    "        pts = [pt1, pt2, pt3]\n",
    "\n",
    "        # draw the Triangulation\n",
    "        cv2.line(img, pt1, pt2, (0, 0, 255), 2)\n",
    "        cv2.line(img, pt2, pt3, (0, 0, 255), 2)\n",
    "        cv2.line(img, pt1, pt3, (0, 0, 255), 2)\n",
    "\n",
    "        index = []\n",
    "        #Get face-points (from 68 face detector) by coordinates\n",
    "        for i in range(3):\n",
    "            for j in range(0, len(points)):\n",
    "                if(pts[i][0] == points[j][0] and pts[i][1] == points[j][1]):\n",
    "                    index.append(j)\n",
    "        # Three points form a triangle\n",
    "        if len(index) == 3:\n",
    "            delaunayTri_indexes.append((index[0], index[1], index[2]))\n",
    "\n",
    "    return delaunayTri_indexes, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(788, 771, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = 'images/original_images/donald_trump_meme.jpg'\n",
    "img = cv2.imread(image)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "<built-in method insert of cv2.Subdiv2D object at 0x7f6475529870> returned NULL without setting an error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-76ac3f9aa018>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msubdiv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSubdiv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msubdiv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlandmark_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtraingle_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubdiv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetTriangleList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtraingle_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in method insert of cv2.Subdiv2D object at 0x7f6475529870> returned NULL without setting an error"
     ]
    }
   ],
   "source": [
    "rect = (0, 0, img.shape[1], img.shape[0])\n",
    "subdiv = cv2.Subdiv2D(rect)\n",
    "subdiv.insert(landmark_points)\n",
    "traingle_list = subdiv.getTriangleList()\n",
    "traingle_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = traingle_list[0]\n",
    "t\n",
    "pt1 = (t[0], t[1])\n",
    "pt2 = (t[2], t[3])\n",
    "pt3 = (t[4], t[5])\n",
    "\n",
    "pts = [pt1, pt2, pt3]\n",
    "pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = []\n",
    "pts.append(pt1)\n",
    "pts.append(pt2)\n",
    "pts.append(pt3)\n",
    "pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.getAffineTransform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hullIndex = cv2.convexHull(np.array(landmark_points), returnPoints = False)\n",
    "hullIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hullIndex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyConvexHull(points):\n",
    "    \n",
    "    hullIndex = cv2.convexHull(np.array(points), returnPoints = False)\n",
    "    \n",
    "    hull = []\n",
    "    for i in range(len(hullIndex)):\n",
    "        hull.append(landmark_points[int(hullIndex[i])])\n",
    "    \n",
    "    return hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = 'images/original_images/donald_trump.jpg'\n",
    "image2 = 'images/original_images/baby.jpg'\n",
    "\n",
    "img1 = cv2.imread(image1)\n",
    "img2 = cv2.imread(image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_points1, _ = landmark_detection(image1)\n",
    "landmark_points2, _ = landmark_detection(image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hull1 = applyConvexHull(landmark_points1)\n",
    "hull2 = applyConvexHull(landmark_points2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hull1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hull2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1warped = np.array(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img1warped.shape)\n",
    "print(img1warped.dtype)\n",
    "type(img1warped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img2.shape)\n",
    "print(img2.dtype)\n",
    "type(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([img2.shape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.copy(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "y = x\n",
    "z = np.copy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0] = 10\n",
    "x[0] == y[0]\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0] == z[0]\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# landmark detection of multiple face in an images\n",
    "def landmark_detection(image):\n",
    "\n",
    "    # laod an image then convert it to grey scale\n",
    "    img = cv2.imread(image)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # detect the face then find the landmarks\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "    faces = detector(img_gray)\n",
    "    for face in faces:\n",
    "        landmarks = predictor(img_gray, face)\n",
    "        landmark_points = []\n",
    "        for n in range(68):\n",
    "            x = landmarks.part(n).x\n",
    "            y = landmarks.part(n).y\n",
    "            landmark_points.append((int(x), int(y)))\n",
    "\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "\n",
    "\n",
    "    return landmark_points, img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
